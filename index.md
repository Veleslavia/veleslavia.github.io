<style>
table, th, td {
   border: none!important;
}
blockquote {
    font-style: normal
}
</style>

[About](#about) | [Career](#career) | [Publications](#publications) | [Research](#research) | [Contacts](#contacts)  

<img align="left" width="150" height="150" src="/assets/img/foto.jpeg" style="margin:0px 0px 0px 0px">

<p align="center"> <br />
Olga Slizovskaia <br />
Associate Principal AI Scientist <br />
<a href="https://www.astrazeneca.com/r-d/data-science-and-ai.html">AstraZeneca, Centre for AI</a> <br />
Av. Diagonal, 615  <br />
Les Corts, 08028 Barcelona
</p> 

<br />
Olga is a machine learning researcher with expertise in source separation, sound localization, voice conversion, music processing, and speech synthesis using deep learning and machine learning algorithms. In addition, Olga has experience in multimodal and audio-visual learning, time series analysis, and anomaly detection.

---

## About
Olga joined [AstraZeneca, Centre for AI](https://www.astrazeneca.com/r-d/data-science-and-ai.html) as an Associate Principal AI Scientist in January 2023 to develop new and innovative approaches to analyse and interpret audio data, leveraging the latest techniques in deep learning and machine learning fields. Her current work is focused on audio biomarkers discovery research and respiratory sound analysis. 

Previously, she served as a Research Engineer at [Voctro Labs](https://www.linkedin.com/company/voctro-labs/about/) (acquired by Voicemod) and was awarded a 3-year R&D Torres Quevedo Fellowship in 2022. She interned at [Mitsubishi Electric Research Laboratories](https://www.merl.com/) under the supervision of [Gordon Wichern](https://www.merl.com/people/wichern) and [Jonathan Le Roux](https://www.jonathanleroux.org/), and at [Telefonica Research](https://twitter.com/TEFresearch) collaborating with [Joan Serrà](https://serrjoa.github.io/) and [Ilias Leontiadis](https://leontiadis.net/). 

Olga received her PhD from the University of Pompeu Fabra in 2020, supervised by [Emilia Gómez](https://emiliagomez.com/) and [Gloria Haro](https://scholar.google.com/citations?user=edEh3UMAAAAJ&hl=en). Her research focused on audio-visual deep learning methods and was supported by the María de Maeztu Unit of Excellence. She earned her Master’s degree in Applied Mathematics and Computer Science from [Moscow State University](https://cs.msu.ru/en) in 2013.

In her free time, Olga enjoys visiting bakeries, mountaineering, spending time with her dog, and Irish dancing. 

---

## Career
**2023 -- Associate Principal AI Scientist** - [AstraZeneca, Centre for AI](https://www.astrazeneca.com/r-d/data-science-and-ai.html)  
- Audio biomarkers discovery research and respiratory sound analysis with deep learning and machine learning techniques

**2020 -- Research Engineer** - [Voctro Labs](https://www.linkedin.com/company/voctro-labs/about/) (acquired by Voicemod)
- Real-time voice processing and voice conversion R&D for Voicemod Voice Changer. Optimizing autoregressive models to meet low latency and low resource utilization requirements. Awarded a 3 years R&D Torres Quevedo scholarship.

**2021 -- Research Intern** - [Mitsubishi Electric Research Laboratories](https://www.merl.com/)
- Research project on conditioned sound event localization and detection under the supervision of [Gordon Wichern](https://www.merl.com/people/wichern) and [Jonathan Le Roux](https://www.jonathanleroux.org/).

**2020 -- Doctoral Thesis Defense** - [Pompeu Fabra University](https://www.upf.edu/)
- PhD thesis: "Audio-visual deep learning methods for musical instrument classification and separation" under the supervision of [Emilia Gómez](https://emiliagomez.com/) and [Gloria Haro](https://scholar.google.com/citations?user=edEh3UMAAAAJ&hl=en)

**2018 -- Research Intern** - [Telefonica Research](https://twitter.com/TEFresearch)
- Anomaly detection in time-series data using likelihood-based generative models (normalizing flows) collaborating with [Joan Serrà](https://serrjoa.github.io/) and [Ilias Leontiadis](https://leontiadis.net/)

**2015 -- Data Engineer** - [Data-Centric Alliance](https://www.linkedin.com/company/d-c-a-data-centric-alliance/about/)
- Design and development of machine learning models for online advertising

**2013 -- Data Engineer** - [Zvooq LLC](https://zvuk.com/about) (now Zvuk)
- Music data ingestion infrastructure development and support

**2013 -- Master’s degree** - Applied Mathematics and Computer Science, [Moscow State University](https://cs.msu.ru/en)

---

## Publications

### Complete list
For an always updated list of my publications visit my [Google Scholar Profile](https://scholar.google.com/citations?user=Kxh4-s8AAAAJ&hl=en)

### Recent

> **Method and System for Sound Event Localization and Detection**  
> G. Wichern, O. Slizovskaia, J. Le Roux  
> US Patent App. 17/687,866 (2023)

> **Locate this, not that: Class-conditioned sound event doa estimation**  
> O. Slizovskaia, G. Wichern, Z.-Q. Wang, J. Le Roux  
> In IEEE ICASSP (2022)  
> [[arXiv]](https://arxiv.org/abs/2203.04197) [[doi]](https://doi.org/10.1109/ICASSP43922.2022.9747604)

> **Conditioned source separation for music instrument performances**  
> O. Slizovskaia, G. Haro, E. Gómez  
> The IEEE/ACM Transactions on Audio, Speech, and Language Processing (2021)  
> [[arXiv]](https://arxiv.org/abs/2004.03873) [[doi]](https://doi.org/10.1109/TASLP.2021.3082331)

> **Input complexity and out-of-distribution detection with likelihood-based generative models**  
> J. Serrà, D. Álvarez, V. Gómez, O. Slizovskaia, J. F. Núñez, J. Luque  
> In The 2020 International Conference on Learning Representations (ICLR) (2020)  
> [[arXiv]](https://arxiv.org/abs/1909.11480) [[openreview]](https://openreview.net/forum?id=SyxIWpVYvr)

---

## Research

### Current Research Interests

My research focuses on developing machine learning and deep learning techniques for improving machine perception of audio signals. This includes speech recognition, sound event detection, and music information retrieval.

### CV
- [CV](/assets/OlgaSlizovskaiaCV.pdf) updated Feb 2024.

### Dissimination materials
- PhD Thesis:  
**Audio-visual deep learning methods for musical instrument classification and separation**  
[[Manuscript]](/assets/thesis/thesis.pdf) [[Slides]](https://github.com/Veleslavia/defense-slides) [[Defense Video]](https://www.youtube.com/watch?v=FmgiMzkabrA)
- **[Conditioned Source Separation for Music Instrument Performances](https://veleslavia.github.io/conditioned-u-net)**

### Code
- You can check my [GitHub profile](https://github.com/veleslavia) for open-source code for some projects.

---

## Contacts

For collaboration or any inquiries, you can reach out to me:

- Email: olga [dot] slizovskaia [at] astrazeneca [dot] com
- LinkedIn: [Olga Slizovskaia](https://www.linkedin.com/in/olga-slizovskaia)
- GitHub: [Veleslavia](https://github.com/Veleslavia)
